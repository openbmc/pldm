{
  "comments": [
    {
      "unresolved": true,
      "key": {
        "uuid": "63c9aa1b_6e4c7efd",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2024-11-01T09:54:18Z",
      "side": 1,
      "message": "The terminus supports many PLDM command types for each type it will support many commands.\nI don\u0027t think return Error and un-map the terminus at this step is reasonable.\nWhy the PLDM command is failed? What is the reason? If the connection is not stable or the terminus is not stable then we should fix the terminus but not repeat retry to discovery the terminus.",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "58dc1f05_017f4e6b",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-11-01T10:19:39Z",
      "side": 1,
      "message": "The \"get PLDM command failed\" issue occurs during a request timeout.\nCould it be that with an overload of requests, the PLDM device responds within the timeout, but PLDM cannot process it in time, marking the request as failed?\n\nWhen a get PLDM command fails, it results in an incorrect initialization of the PLDM device, and if the failed command is for PDR, this can cause the PLDM device to disappear with no further chance for sensor polling.\nShould the request timeout duration be extended in this case?\n\nYour advice would be appreciated. Thank you.",
      "parentUuid": "63c9aa1b_6e4c7efd",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1cd3f0a6_ee7b81ee",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-11-01T11:42:53Z",
      "side": 1,
      "message": "Mark as resolved",
      "parentUuid": "58dc1f05_017f4e6b",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "2a5a16eb_33999585",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2024-11-01T12:02:20Z",
      "side": 1,
      "message": "The pldm support the option to set the timeout in access terminus and also number of retry when there is failure. This command is sent in the discovery flow, no sensor polling, no event handling at this moment. Then why it is time out?",
      "parentUuid": "1cd3f0a6_ee7b81ee",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "308b42e7_e7579ae1",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-11-06T01:51:33Z",
      "side": 1,
      "message": "Are you referring to the instance-id-expiration-interval (request timeout option) and number-of-request-retries (retry attempt count) in the meson.options?\nCould modifying the instance-id-expiration-interval potentially lead to a shortage due to slow release of instance IDs?\nWhile the number-of-request-retries is currently set to 2, I haven\u0027t observed a retry mechanism in the current PLDM execution logs. Is there a way to enable immediate retry on encountering a PLDM error?\n\nDo you think modifying these two parameters would be beneficial, or might the impact be too broad? Could we configure these parameters specifically for our project layer instead?\n\nIn our system, during startup, the BMC interfaces with approximately 16 PLDM devices, requiring simultaneous communication and initialization. Each device has nearly a hundred sensors and services like phosphor-pid-control that also need PLDM information. From my understanding, processRxMsg handles incoming requests and responses one by one. Is it possible that the transmission is completed much sooner, but due to processRxMsg taking too long, it fails to process the request in time?\n\nThank you very much!",
      "parentUuid": "2a5a16eb_33999585",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "94cb69f3_8007bee0",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2024-11-06T02:08:15Z",
      "side": 1,
      "message": "\u003e Are you referring to the instance-id-expiration-interval (request timeout option) and number-of-request-retries (retry attempt count) in the meson.options?\n\u003e Could modifying the instance-id-expiration-interval potentially lead to a shortage due to slow release of instance IDs?\n\u003e While the number-of-request-retries is currently set to 2, I haven\u0027t observed a retry mechanism in the current PLDM execution logs. Is there a way to enable immediate retry on encountering a PLDM error?\n\nDid you try those option yet?\n\n\u003e \n\u003e Do you think modifying these two parameters would be beneficial, or might the impact be too broad? Could we configure these parameters specifically for our project layer instead?\n\u003e \n\u003e In our system, during startup, the BMC interfaces with approximately 16 PLDM devices, requiring simultaneous communication and initialization. Each device has nearly a hundred sensors and services like phosphor-pid-control that also need PLDM information. From my understanding, processRxMsg handles incoming requests and responses one by one. Is it possible that the transmission is completed much sooner, but due to processRxMsg taking too long, it fails to process the request in time?\n\nWhat is the error you see in the failure case?\nIf the failure happen in the discovery phase because there are too much devices. I think it is better to order the binding devices one by one instead of binding all at one.\nMoreover, if the `processRxMsg handles incoming requests and responses` then I can\u0027t handle the `pldmd` communication when `pldmd` in handling sensor polling for all of 16 devices.\n\nFailure in `getting PLDM commands supports` of one PLDM type does not mean the device not good to unmap it and rediscovery it.\n\n\u003e \n\u003e Thank you very much!",
      "parentUuid": "308b42e7_e7579ae1",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "570480a7_eb5e48cf",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-11-08T10:22:56Z",
      "side": 1,
      "message": "\u003e Did you try those option yet?\n\nApologies, but I have not tried modifying the parameters in meson.option yet. Our project requires the OpenBMC build to stay fully aligned with upstream, so I don’t think we can change these options freely.\n\nAlso, I am still unclear on the role of number-of-request-retries in the PLDM code and which part handles the retry. From the logs, it seems that failed requests only attempt once and then fail.\n\n\n\u003e What is the error you see in the failure case?\n\u003e If the failure happen in the discovery phase because there are too much devices. I think it is better to order the binding devices one by one instead of binding all at one.\n\nDuring the discovery process, there are messages such as:\nInstance ID expiry for EID \u002740\u0027 using InstanceID ...\nFailed to Get PLDM Commands for terminus 40, error 4\n\nIf this step fails, it might cause the getPDRs process to assume the get PDR command is unsupported, leading to the PLDM device not initializing properly.\n\n\u003e Moreover, if the `processRxMsg handles incoming requests and responses` then I can\u0027t handle the `pldmd` communication when `pldmd` in handling sensor polling for all of 16 devices.\n\nCould you explain if there is a way to configure or achieve binding devices one by one instead of binding all at once? Is your point that, in our environment, the initialization of so many PLDM devices could indeed overwhelm the PLDM response handling? \n\n\u003e Failure in `getting PLDM commands supports` of one PLDM type does not mean the device not good to unmap it and rediscovery it.\n\nI’m also not clear on whether this means the device should not be unmapped even if it fails. My goal is to ensure that if a timeout occurs during the initialization phase, the PLDM device still has a chance to retry initialization.\n\nThank you very much for your advice.",
      "parentUuid": "94cb69f3_8007bee0",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "9a4599fd_47ae5aa2",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2024-11-10T10:46:28Z",
      "side": 1,
      "message": "\u003e \u003e Did you try those option yet?\n\u003e \n\u003e Apologies, but I have not tried modifying the parameters in meson.option yet. Our project requires the OpenBMC build to stay fully aligned with upstream, so I don’t think we can change these options freely.\n\nYou can change the option in bbappend file. no need to change the code.\nhttps://github.com/openbmc/openbmc/blob/3debd6217b72ecb326d0a7332444c15f5fd7273f/meta-evb/meta-evb-arm/meta-evb-fvp-base/recipes-phosphor/pldm/pldm_%25.bbappend#L7\n\n\u003e \n\u003e Also, I am still unclear on the role of number-of-request-retries in the PLDM code and which part handles the retry. From the logs, it seems that failed requests only attempt once and then fail.\n\nhttps://github.com/openbmc/pldm/blob/29942de32edb454f75abb561538fd8cc8624c61f/meson.options#L121\nWhen the request is failed cause time out, the pldmd will try to send request again `response-time-out` time. response-time-out\u003d2, it means `pldmd` will send the request 3 times.\n\n\u003e \n\u003e \n\u003e \u003e What is the error you see in the failure case?\n\u003e \u003e If the failure happen in the discovery phase because there are too much devices. I think it is better to order the binding devices one by one instead of binding all at one.\n\u003e \n\u003e During the discovery process, there are messages such as:\n\u003e Instance ID expiry for EID \u002740\u0027 using InstanceID ...\n\nhttps://github.com/openbmc/pldm/blob/29942de32edb454f75abb561538fd8cc8624c61f/requester/handler.hpp#L159\nIt means `pldmd` tried to send the request `response-time-out + 1` times with time out `response-time-out` (default 2 seconds) but still no response from the device.\n\nIt seems there is many termini in the same MCTP bus in your system, and there is arbitration lost at the init time when one or some devices is getting PDRs while the others in the discovery phase `GetPLDMCommands`.\nThat why one terminus can\u0027t get the bus to response the request from BMC.\nThat why you need binding the devices one by one. Or increate the time out or retry time. To give the terminus a change to get the bus and response for the request from BMC.\n\n\u003e Failed to Get PLDM Commands for terminus 40, error 4\n\u003e \n\u003e If this step fails, it might cause the getPDRs process to assume the get PDR command is unsupported, leading to the PLDM device not initializing properly.\n\u003e \n\u003e \u003e Moreover, if the `processRxMsg handles incoming requests and responses` then I can\u0027t handle the `pldmd` communication when `pldmd` in handling sensor polling for all of 16 devices.\n\u003e \n\u003e Could you explain if there is a way to configure or achieve binding devices one by one instead of binding all at once? Is your point that, in our environment, the initialization of so many PLDM devices could indeed overwhelm the PLDM response handling? \n\nYes. You can call MCTP binding one by one, the next devices will be bind when the previous devices is done by checking the existing of terminus sensors.\nYou only need this when the terminus in the same I2C bus.\n\nhttps://gerrit.openbmc.org/c/openbmc/openbmc/+/75302/6/meta-ampere/meta-mitchell/recipes-ampere/host/ampere-mctp-i2c-binding/ampere_mctp_i2c_binding.sh#95\nThis is the way Ampere binding the terminus in the same bus one by one.\n\n\u003e \n\u003e \u003e Failure in `getting PLDM commands supports` of one PLDM type does not mean the device not good to unmap it and rediscovery it.\n\u003e \n\u003e I’m also not clear on whether this means the device should not be unmapped even if it fails. My goal is to ensure that if a timeout occurs during the initialization phase, the PLDM device still has a chance to retry initialization.\n\nMy idea when only prints the error in `GetPLDMCommands` of one terminus is\n1. If the devices is ready for `GetPLDMTypes` commands that means it is ready for pldm requests. There is no reason to failed for next commands in the discovery phase. If there is failure then there are some things wrong with the OEM systems. In that case, print errors to allow the developer debug.\n\n2. The terminus can support many PLDM types, Base (0x0), Platform and control (0x2), FRU, BIOS. Failure in `GetPLDMCommands` of BIOS or FRU type does not mean the terminus is not functional and can\u0027t response its status. So print the error is enough.\n\nYou can bring your idea to the `pmci` discord group to discuss about your patch set. If the community agree with your proposal then we will merge it.\n\nMy idea is simple `If the devices if failed for PLDM commands in the discovery phase. Then there is some things wrong with the system. Print error to debug instead of continuous retrying to discovery`\n\nBecause if the system can\u0027t response for some basis PLDM commands in the discovery phase, then in will fault when start polling the many of PLDM sensor/status/effecter or handle events because there will be more PLDM request from BMC at this phase.\n\n\u003e \n\u003e Thank you very much for your advice.",
      "parentUuid": "570480a7_eb5e48cf",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "8c6cbe7d_08eba421",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-11-14T10:59:08Z",
      "side": 1,
      "message": "Thank you very much for your suggestions and explanations.\nI will review these suggestions first.\n\nThanks!",
      "parentUuid": "9a4599fd_47ae5aa2",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "0a758a9a_f0ec528a",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-12-04T09:52:23Z",
      "side": 1,
      "message": "Thank you for your previous explanation.\nBased on your guidance, I have adjusted the system to handle MCTP EP D-Bus objects one by one and set `instance-id-expiration-interval\u003d6`, the occurrence of request timeouts causing init failures has indeed decreased.\nHowever, it still happens occasionally, and currently, the `instance-id-expiration-interval` cannot be increased further due to the meson.option max setting of 6.\n\nI would like to reconfirm:\nWith the settings:\n- `instance-id-expiration-interval\u003d6`\n- `number-of-request-retries\u003d2`\n- `response-time-out\u003d2000`\n\nDoes this mean that within the 6-second interval of an instance, a maximum of 3 requests can be sent every 2 seconds?\nIf so, why is the default setting for `instance-id-expiration-interval` 5 and not 6? If it is set to 5, it seems that only the response received within 1 second of the third request would not be considered a timeout, while responses received within 1-2 seconds would be considered timeouts.\n\nIf I adjust `response-time-out` to 4800, should I set `number-of-request-retries` to 1, and does this mean that the response to the second request must be received within 1.2 seconds to avoid being considered a timeout?\nIf `number-of-request-retries` remains at 2, what would be the impact?\n\nAdditionally, I would like to ask about the behavior of PLDM when sending these instance-based requests.\nDoes it wait for one instance to complete or timeout before sending the next one? Is it possible for different instances to send requests simultaneously?\nAnd for the requests retried every 2 seconds, is there a possibility of multiple requests being sent simultaneously?\n\nAlso, I would like to confirm if the target socket for `pldmTransport-\u003esendMsg` is established by the MCTP driver based on the EID.\nDoes the MCTP driver still collect requests from different sockets and process them in FIFO order?\n\nThank you very much for your guidance!",
      "parentUuid": "8c6cbe7d_08eba421",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "bd14e9fb_7766084c",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1000945
      },
      "writtenOn": "2024-12-04T11:34:49Z",
      "side": 1,
      "message": "\u003e Thank you for your previous explanation.\n\u003e Based on your guidance, I have adjusted the system to handle MCTP EP D-Bus objects one by one and set `instance-id-expiration-interval\u003d6`, the occurrence of request timeouts causing init failures has indeed decreased.\n\u003e However, it still happens occasionally, and currently, the `instance-id-expiration-interval` cannot be increased further due to the meson.option max setting of 6.\n\u003e \n\u003e I would like to reconfirm:\n\u003e With the settings:\n\u003e - `instance-id-expiration-interval\u003d6`\n\u003e - `number-of-request-retries\u003d2`\n\u003e - `response-time-out\u003d2000`\n\u003e \n\u003e Does this mean that within the 6-second interval of an instance, a maximum of 3 requests can be sent every 2 seconds?\n\u003e If so, why is the default setting for `instance-id-expiration-interval` 5 and not 6? If it is set to 5, it seems that only the response received within 1 second of the third request would not be considered a timeout, while responses received within 1-2 seconds would be considered timeouts.\n\u003e \n\u003e If I adjust `response-time-out` to 4800, should I set `number-of-request-retries` to 1, and does this mean that the response to the second request must be received within 1.2 seconds to avoid being considered a timeout?\n\u003e If `number-of-request-retries` remains at 2, what would be the impact?\n\nI did not notify about `instance-id-expiration-interval` setting before.\nLook at https://github.com/openbmc/pldm/blob/09fb89c9cab82402d408af00054df78c375c3e79/requester/request.hpp#L59 you can see that the `RequestRetryTimer` does not include `instance-id-expiration-interval`.\nAs my opinion, `instance-id-expiration-interval` should equal (`number-of-request-retries` + 1)*`response-time-out`\nMaybe you can ask in `pmci` discord group.\n\n\u003e \n\u003e Additionally, I would like to ask about the behavior of PLDM when sending these instance-based requests.\n\u003e Does it wait for one instance to complete or timeout before sending the next one? Is it possible for different instances to send requests simultaneously?\n\nAs the pldm base spec, there should only one pldm request to endpoint per time. So `pldmd` will wait for one instance to complete or timeout before sending the next one. You can check this commit to understand my comments.\nhttps://github.com/openbmc/pldm/commit/4ddee3a0fda62e647cadafe07062d10e9db275b4\n\n\u003e And for the requests retried every 2 seconds, is there a possibility of multiple requests being sent simultaneously?\n\nNo, there is not.\n\n\u003e \n\u003e Also, I would like to confirm if the target socket for `pldmTransport-\u003esendMsg` is established by the MCTP driver based on the EID.\n\u003e Does the MCTP driver still collect requests from different sockets and process them in FIFO order?\n\nI think so. But it is better to ask in `pmci` discord team.\n\n\u003e \n\u003e Thank you very much for your guidance!\n\n\nI think you can bring the Patch set to `pmci` for more discussion.\nATM, I don\u0027t know how to handle this patch set.",
      "parentUuid": "0a758a9a_f0ec528a",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "94d344e4_59cc70e7",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-12-06T07:54:47Z",
      "side": 1,
      "message": "Thank you very much for your patient explanation.\nI will ask for opinions about this patch on Discord.\nThanks!",
      "parentUuid": "bd14e9fb_7766084c",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": true,
      "key": {
        "uuid": "c2283457_169c2f3f",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1000206
      },
      "writtenOn": "2024-12-10T04:37:58Z",
      "side": 1,
      "message": "These are my two scents on the problem:\n\n`GetPLDMCommands` is a mandatory command that should be supported for a valid pldm terminus (as per pldm base spec DSP0240).\n\n`GetPLDMCommands` command would return the supported pldm commands per PLDM Type. The way i think its supposed to work is : \n\n1. requester sends `GetPLDMTypes` commnand  -  responder would return which command types are supported. {say for example it returned `base`, `fru`, `platform` }\nrequester sends GetPLDMCommands on each type that was returned in the GetPLDMTypes command like:\n\n`GetPLDMCommands` - for `fru`  - if that returns success  -\u003e this would mean we can talk PLDM fru commands {like `GetFRURecordTableMetadata`,`GetFRURecordTable`, `GetFRURecordByOption` } to the remote end.\n\n`GetPLDMCommands` - for `platform`  - if that returns `ERROR`   -\u003e  this would mean something bad happened on the other side.\nat this point if we send a `GetPLDMTypes` again - that might not even return platform - so , i think its reasonable to basically think that the remote endpoint is `not capable to talk platform commands` - but that does not mean that we cannot talk to the remote endpoint at all right ? (we can still talk base, fru, and what ever is supported)\n....\nso , we should not basically mark the endpoint as problamatic and remove it from the map. Rather we should handle it gracefully and stop sending the commands that the remote endpoint is not capable. despite all this even if we accidentally send the commands, the responder can return back `ERROR_UNSUPPORTED_PLDM_CMD`",
      "parentUuid": "94d344e4_59cc70e7",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    },
    {
      "unresolved": false,
      "key": {
        "uuid": "1ee20961_cc5496d6",
        "filename": "platform-mc/terminus_manager.cpp",
        "patchSetId": 1
      },
      "lineNbr": 368,
      "author": {
        "id": 1002134
      },
      "writtenOn": "2024-12-11T02:12:15Z",
      "side": 1,
      "message": "Thank you very much for your explanation.\nI understand that we should not consider the entire PLDM device initialization as failed just because some Get PLDM Commands failed.\n\nThe reason I initially thought of removing it from the map was due to concerns that a request timeout during the Get PLDM Commands might result in an incomplete PLDM device initialization.\nBy removing and exiting the task, the MCTP info remains in the queue, allowing it to be reinitialized as a complete PLDM device when another interface added signal triggers the task.\n\nI will consider other ways to handle this situation.\nThanks!",
      "parentUuid": "c2283457_169c2f3f",
      "revId": "9b702cccc06ff7aae78154fa3007aa2b588dab5e",
      "serverId": "adbd0a64-1f21-4d83-b585-671fe73cb6e4"
    }
  ]
}